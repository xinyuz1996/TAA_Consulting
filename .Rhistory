return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
lst <- nlm(function(lambda){-log.like(y,x)},0.01)
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lst
lambda0_minimum <- log.like.lambda0(y)
lambda0_minimum
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambdaMLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambdaMLE)
}
i
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambdaMLE)
}
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambda_MLE)
}
mean(results[,3])
?cov
covhat <- cov(results)
covhat
100*convhat
covhat <- cov(results)
100*covhat
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sqrt(sigma2MLE),lambda_MLE)
}
covhat <- cov(results)
100*covhat
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(1)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sqrt(sigma2MLE),lambda_MLE)
}
covhat <- cov(results)
100*covhat
library(iso)
install.packages("Iso")
library(Iso)
y <- c(0.38753188, 0.33352923, 1.69926631, 1.51233891, 3.71256346,
6.54700165, 6.78007386, 8.3102987 , 7.96376751, 8.37754041)
pava(y)
k <- 3
nc <- 10
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
1-pchisq(qchisq(0.95,k-1),2,nc)
k <- 3
nc <- 10
1-pchisq(qchisq(0.95,k-1),2,nc)
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 10
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 20
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
k <- 3
nc <- 10
1-pchisq(qchisq(0.95,k-1),2,nc)
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 10
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 20
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
pbinom(7,20,0.3)
pbinom(7,20,0.3)-pbinom(1,20,0.3)
dbinom(7,20,0.3)
pbinom(4,15,0.5)+1-pbinom(10,15,0.5)
pbinom(7,15,0.5)
dbinom(6,15,0.5)
pbinom(12,15,0.5)-pbinom(2,15,0.5)
pbinom(4,15,0.5)
pbinom(4,15,0.5)-pbinom(2,15,0.5)+pbinom(12,15,0.5)-pbinom(10,15,0.5)
0.1184692*0.9926147
1-pbinorm(19,25,0.75)
1-pbinom(19,25,0.75)
(4^2-2^2)/50+2*(5^2-4^2)/50
10-sqrt(50/3)
dbinom(9,10,15/16)
exp(-1)-exp(-(1.5)^3)
(-log(0.25))^(1/3)*5
(-log(0.75))^(1/3)*5
(-log(0.25))^(1/3)*5-(-log(0.75))^(1/3)*5
1-pnorm((7.5-225*0.05)/sqrt(225*0.05*0.95))
1-pnorm((8-225*0.05)/sqrt(225*0.05*0.95))
1-pnorm((7-225*0.05)/sqrt(225*0.05*0.95))
pnorm((14.5-225*0.05)/sqrt(225*0.05*0.95))-pnorm((5.5-225*0.05)/sqrt(225*0.05*0.95))
0.2*0.8/1000
sqrt(0.00016)
sqrt(0.2*0.8/1000)
68.3/2+50
qnorm(0.8415)
1.000642*0.01264911+0.2
0.2126572-0.2
0.2+sqrt(0.00016)*qnorm(0.6)
0.6*0.4/100
0.6*0.4/200
qnorm(0.6)
0.2-0.01264911*0.2533471
l1trendfilter <- function(y,lambda,k,dt_perc=1,N=1e5,thetaInit=NULL,
sigma2Init=NULL,alpha=NULL,alphaAdjust=F,
alpha_shape=NULL,alpha_rate=NULL,t=1,correct_manner='none'){
n <- length(y)
D <- getD(k,n)
#prepare the arrays for sample storation
theta_samples <- matrix(0,nrow=N,ncol=n)
sigma2_samples <- rep(0,N)
alpha_samples <- rep(0,N)
#set initial values of theta,sigma2 and alpha
if(is.null(thetaInit)){
theta <- theta_samples[1,] <- y
}else{
theta <- theta_samples[1,] <- thetaInit
}
if(is.null(sigma2Init)){
sigma2 <- sigma2_samples[1] <- 1
}else{
sigma2 <- sigma2_samples[1] <- sigma2Init
}
alpha_samples[1] <- alpha
#ensure that alpha_shape and alpha_rate are specified if alphaAdjust=T
if(alphaAdjust){
if(is.null(alpha_shape)|is.null(alpha_rate)){
stop('alpha_shape and alpha_rate must be specified!')
}
}
#prepare the gradient and proximal operator
gradf <- function(theta){(theta-y)/sigma2}
prox <- function(theta){glmgen::trendfilter(theta,k=k,lambda=lambda*alpha)$beta}
logpilambda <- function(theta,prox_proj_theta){
loglikelihood <- -norm(y-theta,'2')^2/(2*sigma2)-alpha*Matrix::norm(D%*%prox_proj_theta,'1')-norm(theta-prox_proj_theta,'2')^2/(2*lambda)
return(loglikelihood)
}
logpi <- function(theta){-norm(y-theta,'2')^2/(2*sigma2)-alpha*Matrix::norm(D%*%theta,'1')}
#MCMC sampling
pb <- progress::progress_bar$new(
format = "  sampling [:bar] :percent eta: :eta",
total = N-1, clear = FALSE, width= 60)
if(correct_manner=='none'){
for(i in 1:(N-1)){
Lf <- 1/sigma2
thetanew <- MYULA_tstep(theta,lambda,Lf,dt_perc,gradf,prox,t)
theta <- theta_samples[i+1,] <- thetanew
sigma2 <- sigma2_samples[i+1] <- invgamma::rinvgamma(1, n/2, rate = sum((y-theta)^2)/2)
alpha_samples[i+1] <- alpha
pb$tick()
}
}else{
accept_number <- 0
for(i in 1:(N-1)){
Lf <- 1/sigma2
if(correct_manner=='approximate'){
result <- MYMALA(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='approximate',logpilambda=logpilambda)
}else{
result <- MYMALA(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='exact',logpi=logpi)
}
theta <- theta_samples[i+1,] <- result$thetanew
if(result$accept){
accept_number <- accept_number+1
}
sigma2 <- sigma2_samples[i+1] <- invgamma::rinvgamma(1, n/2, rate = sum((y-theta)^2)/2)
if(alphaAdjust){
alpha <- rgamma(1,alpha_shape,alpha_rate+Matrix::norm(D%*%theta,'1'))
}
alpha_samples[i+1] <- alpha
pb$tick()
}
print(sprintf("%s%% of theta MCMC iterates accepted (%s total iterates)",100*accept_number/N,N))
}
return(list(theta_samples=theta_samples,sigma2_samples=sigma2_samples,
alpha_samples=alpha_samples))
}
MYMALA <- function(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='approximate',
logpilambda=NULL,logpi=NULL){
n <- length(theta)
#L is the lipschitz constant of the gradient of U
L <- Lf+1/lambda
#same gamma as in MYULA paper
gamma <- dt_perc/L
#gradient of f at current iterate theta
gradf_theta <- gradf(theta)
#proximal projection of current iterate theta
prox_proj_theta <- prox(theta)
#the constant part of the transition kernel
normal_mean_forward <- (1-gamma/lambda)*theta-gamma*gradf_theta+gamma/lambda*prox_proj_theta
#add Gaussian noise to get the new MCMC iterate
thetanew <- normal_mean_forward + sqrt(2*gamma)*rnorm(n)
accept <- T
#gradient of f at new iterate thetanew
gradf_thetanew <- gradf(thetanew)
#proximal projection of new iterate thetanew
prox_proj_thetanew <- prox(thetanew)
#the constant part of the inverse transition kernel
normal_mean_backward <- (1-gamma/lambda)*thetanew-gamma*gradf_thetanew+gamma/lambda*prox_proj_thetanew
log_q_diff <- (norm(thetanew-normal_mean_forward,'2')^2-norm(theta-normal_mean_backward,'2')^2)/(4*gamma)
if(correct_manner=='approximate'){
if(is.null(logpilambda)){
stop('logpilambda must be specified for approximate correction')
}
log_pilambda_diff <- logpilambda(thetanew,prox_proj_thetanew)-logpilambda(theta,prox_proj_theta)
log_ratio <- min(0,log_pilambda_diff+log_q_diff)
}else{
if(is.null(logpi)){
stop('logpi must be specified for exact correction')
}
log_pi_diff <- logpi(thetanew)-logpi(theta)
log_ratio <- min(0,log_pi_diff+log_q_diff)
}
#actual correction step
if(log(runif(1))>log_ratio){
thetanew <- theta
accept <- FALSE
}
return(list(thetanew=thetanew,accept=accept))
}
f <- Vectorize(function(x){if(x<=5){x} else if(x<=15){10-x} else{x-20}})
x <- seq(0,20,length=100)
y <- f(x)+rnorm(100)
getD <- function(k, n){
D <- Matrix::sparseMatrix(i=c(1:(n-1),1:(n-1)),j=c(1:(n-1),2:n),
x=c(rep(-1,n-1),rep(1,n-1)),dims=list(n-1,n))
if(k>=1){
for(i in 1:k){
leftD <- Matrix::sparseMatrix(i=c(1:(n-i-1),1:(n-i-1)),j=c(1:(n-i-1),2:(n-i)),
x=c(rep(-1,n-i-1),rep(1,n-i-1)),dims=list(n-i-1,n-i))
D <- leftD %*% D
}}
return(D)
}
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=T,alpha_shape=100,alpha_rate=1,correct_manner='exact')
alpha_samples <- samples$alpha_samples
mean(alpha_samples)
posterior_means <- apply(theta_samples,2,mean)
sigma2_samples <- samples$sigma2_samples
theta_samples <- samples$theta_samples
posterior_medians <- apply(theta_samples,2,quantile,probs=0.05)
lower_conflim <- apply(theta_samples,2,quantile,probs=0.025)
upper_conflim <- apply(theta_samples,2,quantile,probs=0.975)
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_means,type='l',col='blue')
ines(x,posterior_medians,type='l',col='blue')
lines(x,posterior_medians,type='l',col='blue')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='exact')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='exact')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='approximate')
alpha_samples <- samples$alpha_samples
theta_samples <- samples$theta_samples
sigma2_samples <- samples$sigma2_samples
posterior_medians <- apply(theta_samples,2,quantile,probs=0.05)
lower_conflim <- apply(theta_samples,2,quantile,probs=0.025)
upper_conflim <- apply(theta_samples,2,quantile,probs=0.975)
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
posterior_medians <- apply(theta_samples,2,quantile,probs=0.5)
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
hist(alpha_samples,breaks=100,col='blue',main='')
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
hist(sigma2_samples,breaks=100,xlab='sigma2',col='blue',main='')
abline(v=1, col='red')
library(devtools)
load_all()
data <- read_delim("./data/tabular data_impute.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
library(readr)
setwd('C:/Users/Qiang/Desktop/Quick access/course/TAA_Consulting')
data <- read_delim("./data/tabular data_impute.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
View(data)
Y <- data[,c(1,2,3)]
multi_reg <- lm(Y~-1+.,data=data)
Y <- data.matrix(data[,c(1,2,3)])
multi_reg <- lm(Y~-1+.,data=data)
multi_reg
multi_reg <- lm(Y1_initiation~-1+.,data=data)
multi_reg
X <- data.matrix(data[,-c(1,2,3)])
View(X)
multi_reg <- lm(Y1_initiation~.-1,data=X)
X <- data[,-c(1,2,3)]
multi_reg <- lm(Y1_initiation~.-1,data=X)
multi_reg <- lm(Y~.-1,data=X)
multi_reg
lm(Y[,1]~.-1,data=X)
mvsum[[1]]
mvsum <- summary(multi_reg)
mvsum[[1]]
mvsum[[2]]
mvsum[[3]]
multi_reg1 <- lm(Y~.-1-X1_readiness,data=X)
anova(multi_reg, multi_reg1, test="Wilks")
multi_reg <- lm(Y~.-1,data=X)
multi_reg1 <- lm(Y~.-1-X1_readiness,data=X)
anova(multi_reg, multi_reg1, test="Wilks")
anova(multi_reg, multi_reg1, test="Pillai")
anova(multi_reg, multi_reg1, test="Hotelling-Lawley")
anova(multi_reg, multi_reg1, test="Roy")
anova(multi_reg, multi_reg1, test="Wilks")
anova(multi_reg, multi_reg1, test="Pillai")
anova(multi_reg, multi_reg1, test="Hotelling-Lawley")
anova(multi_reg, multi_reg1, test="Roy")
)
multi_reg2 <- lm(Y~.-1-X2_integration,data=X)
anova(multi_reg, multi_reg2, test="Wilks")
anova(multi_reg, multi_reg2, test="Pillai")
anova(multi_reg, multi_reg2, test="Hotelling-Lawley")
anova(multi_reg, multi_reg2, test="Roy")
multi_reg3 <- lm(Y~.-1-X3_firmsize,data=X)
multi_reg3 <- lm(Y~.-1-X3_firmSize,data=X)
anova(multi_reg, multi_reg3, test="Wilks")
anova(multi_reg, multi_reg3, test="Pillai")
anova(multi_reg, multi_reg3, test="Hotelling-Lawley")
anova(multi_reg, multi_reg3, test="Roy")
multi_reg4 <- lm(Y~.-1-X4_global,data=X)
anova(multi_reg, multi_reg4, test="Wilks")
anova(multi_reg, multi_reg4, test="Pillai")
anova(multi_reg, multi_reg4, test="Hotelling-Lawley")
anova(multi_reg, multi_reg4, test="Roy")
multi_reg5 <- lm(Y~.-1-X5_manag,data=X)
anova(multi_reg, multi_reg5, test="Wilks")
anova(multi_reg, multi_reg5, test="Pillai")
anova(multi_reg, multi_reg5, test="Hotelling-Lawley")
anova(multi_reg, multi_reg5, test="Roy")
multi_reg6 <- lm(Y~.-1-X6_compet,data=X)
anova(multi_reg, multi_reg6, test="Wilks")
anova(multi_reg, multi_reg6, test="Pillai")
anova(multi_reg, multi_reg6, test="Hotelling-Lawley")
anova(multi_reg, multi_reg6, test="Roy")
multi_reg7 <- lm(Y~.-1-X7_regulatory,data=X)
anova(multi_reg, multi_reg7, test="Wilks")
anova(multi_reg, multi_reg7, test="Pillai")
anova(multi_reg, multi_reg7, test="Hotelling-Lawley")
anova(multi_reg, multi_reg7, test="Roy")
