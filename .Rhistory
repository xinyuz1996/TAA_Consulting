
fw1 <- function(eta){fw(eta, dataLDL)}
WIJ = sapply(eta_list, fw1)
Left = c(sum(WIJ * y ), sum(WIJ %*% eta_list * y), sum(WIJ %*% (eta_list^2) * y))
w0 = sum(WIJ)
w1 = sum(WIJ %*% eta_list)
w2 = sum(WIJ %*% (eta_list^2))
w3 = sum(WIJ %*% (eta_list^3))
w4 = sum(WIJ %*% (eta_list^4))
Right = matrix(c(w0, w1, w2, w1, w2, w3, w2, w3, w4 ), nrow=3, ncol=3)
alpha = solve(Right) %*% Left
return(alpha)
}
fv <- function(alpha, eta){
c(alpha) %*% c(1, eta, eta^2)
}
alpha = fa(eta_list, dataLDL)
(VQ1 = sapply(eta_list,fv, alpha=alpha))
oneBoot <- function(eta, data, index){
dataLDL = data[index,]
PS1 <- modelObj::fit(object = p1, data = dataLDL, response = dataLDL$A1)
PS2 <- modelObj::fit(object = p2, data = dataLDL, response = dataLDL$A2)
PS3 <- modelObj::fit(object = p3, data = dataLDL, response = dataLDL$A3)
PS4 <- modelObj::fit(object = p4, data = dataLDL, response = dataLDL$A4)
pi1 <- modelObj::predict(object = PS1, type='response')
pi2 <- modelObj::predict(object = PS2, type='response')
pi3 <- modelObj::predict(object = PS3, type='response')
pi4 <- modelObj::predict(object = PS4, type='response')
alpha = fa(eta_list, dataLDL)
V = sapply(eta_list,fv, alpha=alpha)
return(V)
}
boots1 <- function(R=100){
start_time <- Sys.time()
valueBoot <- boot::boot(dataLDL_orig, function(data, index){oneBoot(eta,data, index)}, R = R,  parallel="snow")
end_time <- Sys.time()
(run_time <- end_time - start_time) # 25
valueBoot <- list( valueBoot = valueBoot, run_time=run_time)
filepath = paste("1b",R,".RDS", sep="")
saveRDS(valueBoot, filepath)
valueBoot <- readRDS(filepath)
return(valueBoot)
}
#boots1b = boots1(1000)
boots1b = readRDS("1b100.RDS");boots1b
boots1b = readRDS("1b100.RDS");boots1b
t = boots1b$valueBoot$t
msm =  cbind( boots1b$valueBoot$t0, apply(t, 2, sd) )
dimnames(msm) <- list(paste(eta_list), c("msm_mean","msm_sd"))
R=100
G_comp <- numeric()
for(eta in eta_list){
filepath = paste("../HW2/models/eboots",R,"_ita",eta,".RDS", sep="")
valueBoot <- readRDS(filepath)
t <- valueBoot$valueBoot$t
G_comp <- rbind(G_comp, c(mean(t), sd(t)) )
}
dimnames(G_comp) <- list(paste(eta_list), c("g_mean","g_sd"))
VIPW <- readRDS("../HW2/models/finalB.RDS")[11:22,]
dimnames(VIPW) <- list(paste(eta_list), c("IPW_mean","IPW_sd"))
VIPWs <- readRDS( "../HW2/models/finalC.RDS")[11:22,]
dimnames(VIPWs) <- list(paste(eta_list), c("IPWs_mean","IPWs_sd"))
cbind(msm, G_comp, VIPW, VIPWs)
dataLDL_orig <-
as.data.frame(read_table2(
"../data/LDL.dat",
col_names = FALSE,
col_types = cols(X1 = col_number())
))
names(dataLDL_orig) <-
c("id",    "L1",    "A1",    "L2",    "S2",    "A2",    "L3",    "S3",    "A3",    "L4",    "S4",    "A4",    "L5",    "S5")
dataLDL_orig$Y = -dataLDL_orig$L5
data = dataLDL = dataLDL_orig
# Q41
data_41 = data[dataLDL$S4 == 1,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2 + A3 * L3 + A4 * L4 , data = data_41)
Q41 <-   stepAIC(full.model, scope = list(lower = ~ A4*L4),
direction = "both",
trace = F)
summary(Q41)
par(mfrow = c(1, 4))
graphics::plot(x = Q41)
# Q42
data_42 = data[dataLDL$S4 == 0,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2 + A3 * L3 + A4 * L4 , data = data_42)
Q42 <-   stepAIC(full.model, scope = list(lower = ~ A4*L4),
direction = "both",
trace = F)
summary(Q42)
par(mfrow = c(1, 4))
graphics::plot(x = Q42)
# Q31
data_31 = data[dataLDL$S3 == 1,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2 + A3 * L3 , data = data_31)
Q31 <-   stepAIC(full.model, scope = list(lower = ~ A3*L3),
direction = "both",
trace = F)
summary(Q31)
par(mfrow = c(1, 4))
graphics::plot(x = Q31)
# Q32
data_32 = data[dataLDL$S3 == 0,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2 + A3 * L3, data = data_32)
Q32 <-   stepAIC(full.model, scope = list(lower = ~ A3*L3),
direction = "both",
trace = F)
summary(Q32)
par(mfrow = c(1, 4))
graphics::plot(x = Q32)
# Q21
data_21 = data[dataLDL$S2 == 1,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2 , data = data_21)
Q21 <-   stepAIC(full.model, scope = list(lower = ~ A2*L2),
direction = "both",
trace = F)
summary(Q21)
par(mfrow = c(1, 4))
graphics::plot(x = Q21)
# Q22
data_22 = data[dataLDL$S2 == 0,]
full.model <- lm(Y ~ A1 * L1 + A2 * L2, data = data_22)
Q22 <-   stepAIC(full.model, scope = list(lower = ~ A2*L2),
direction = "both",
trace = F)
summary(Q22)
par(mfrow = c(1, 4))
graphics::plot(x = Q22)
# Q1
Q1 <- lm(Y ~ A1 * L1, data = data)
summary(Q1)
par(mfrow = c(1, 4))
graphics::plot(x = Q1)
q41Main <- buildModelObjSubset(model = ~ A1 + L1 + L2  + A3 + L4 + A1:L1,
solver.method = 'lm',
subset = 'd41',
dp = 4L,
predict.method = 'predict.lm')
q41Cont <- buildModelObjSubset(model = ~ L4,
solver.method = 'lm',
subset = 'd41',
dp = 4L,
predict.method = 'predict.lm')
q42Main <- buildModelObjSubset(model = ~ A2 + A3 + L3 + L4 + A3:L3,
solver.method = 'lm',
subset = 'd42',
dp = 4L,
predict.method = 'predict.lm')
q42Cont <- buildModelObjSubset(model = ~ L4,
solver.method = 'lm',
subset = 'd42',
dp = 4L,
predict.method = 'predict.lm')
q31Main <- buildModelObjSubset(model = ~ L3,
solver.method = 'lm',
subset = 'd31',
dp = 3L,
predict.method = 'predict.lm')
q31Cont <- buildModelObjSubset(model = ~ L3,
solver.method = 'lm',
subset = 'd31',
dp = 3L,
predict.method = 'predict.lm')
q32Main <- buildModelObjSubset(model = ~ L3,
solver.method = 'lm',
subset = 'd32',
dp = 3L,
predict.method = 'predict.lm')
q32Cont <- buildModelObjSubset(model = ~ L3,
solver.method = 'lm',
subset = 'd32',
dp = 3L,
predict.method = 'predict.lm')
q21Main <- buildModelObjSubset(model = ~ A1 + L1 + A1:L1 + L2,
solver.method = 'lm',
subset = 'd21',
dp = 2L,
predict.method = 'predict.lm')
q21Cont <- buildModelObjSubset(model = ~ L2,
solver.method = 'lm',
subset = 'd21',
dp = 2L,
predict.method = 'predict.lm')
q22Main <- buildModelObjSubset(model = ~ L2,
solver.method = 'lm',
subset = 'd22',
dp = 2L,
predict.method = 'predict.lm')
q22Cont <- buildModelObjSubset(model = ~ L2,
solver.method = 'lm',
subset = 'd22',
dp = 2L,
predict.method = 'predict.lm')
q1Main <- buildModelObj(model = ~ L1,
solver.method = 'lm',
predict.method = 'predict.lm')
q1Cont <- buildModelObj(model = ~ L1,
solver.method = 'lm',
predict.method = 'predict.lm')
# Construct feasiable sets
fSet4 <- function(data){
subsets <- list(list("d41",0),
list("d42",c(0,1)))
txOpts <- rep(x = 'd42', times = nrow(x = data))
txOpts[data$S4 == 1] <- "d41"
return(list("subsets" = subsets, "txOpts" = txOpts))
}
fSet3 <- function(data){
subsets <- list(list("d31",0),
list("d32",c(0,1)))
txOpts <- rep(x = 'd32', times = nrow(x = data))
txOpts[data$S3 == 1] <- "d31"
return(list("subsets" = subsets, "txOpts" = txOpts))
}
fSet2 <- function(data){
subsets <- list(list("d21",0),
list("d22",c(0,1)))
txOpts <- rep(x = 'd22', times = nrow(x = data))
txOpts[data$S2 == 1] <- "d21"
return(list("subsets" = subsets, "txOpts" = txOpts))
}
QL4 <- DynTxRegime::qLearn(moMain = list(q41Main, q42Main),
moCont = list(q41Cont, q42Cont),
data = dataLDL,
response = dataLDL$Y,
txName = 'A4',
fSet = fSet4,
verbose = TRUE)
QL3 <- DynTxRegime::qLearn(moMain = list(q31Main, q32Main),
moCont = list(q31Cont, q32Cont),
data = dataLDL,
response = QL4,
txName = 'A3',
fSet = fSet3,
verbose = TRUE)
QL2 <- DynTxRegime::qLearn(moMain = list(q21Main, q22Main),
moCont = list(q21Cont, q22Cont),
data = dataLDL,
response = QL3,
txName = 'A2',
fSet = fSet2,
verbose = TRUE)
QL1 <- DynTxRegime::qLearn(moMain = q1Main,
moCont = q1Cont,
data = dataLDL,
response = QL2,
txName = 'A1',
verbose = TRUE)
summary(dataLDL[,c(2,4,7,10,13)])
(Vopt2b = - estimator(QL1))
valueSearch <- function(eta){
reg <- cbind( (data$L1 > eta),
(data$L2 > eta) * (1 - data$S2),
(data$L3 > eta) * (1 - data$S3),
(data$L4 > eta) * (1 - data$S4) )
Q3a <- value_IPW_se_md(moPS = list(p1, p2, p3, p4),
data = dataLDL,
y = dataLDL$Y,
regime = reg)
value = c( -Q3a$valueHat, Q3a$sigmaHat)
return(value)
}
eta_grid <- seq(10, 300, 10)
# value = sapply(eta_grid, valueSearch)
# resultQ3 = rbind(value, eta_grid)[,order(value[1,])]
resultQ3 <- readRDS("resultQ3.RDS")
resultQ3
summary(dataLDL[,c(2,4,7,10,13)])
Vopt2b
Vopt3b = resultQ3[1,1]
q4 <- modelObj::buildModelObj(model = ~ A1 + L1 + L2 + A3 + A4 + L4 + A1:L1 + A4:L4,
solver.method = 'glm',
predict.method = 'predict.glm')
q3 <- modelObj::buildModelObj(model = ~ A3 + L3 + A3:L3,
solver.method = 'glm',
predict.method = 'predict.glm')
q2 <- modelObj::buildModelObj(model = ~ A1 * L1 + A2 * L2,
solver.method = 'glm',
predict.method = 'predict.glm')
q1 <- modelObj::buildModelObj(model = ~ A1 * L1,
solver.method = 'glm',
predict.method = 'predict.glm')
q4 <- modelObj::buildModelObj(model = ~ A1 + L1 + L2 + A3 + A4 + L4 + A1:L1 + A4:L4,
solver.method = 'glm',
predict.method = 'predict.glm')
q3 <- modelObj::buildModelObj(model = ~ A3 * L3,
solver.method = 'glm',
predict.method = 'predict.glm')
q2 <- modelObj::buildModelObj(model = ~ A1 * L1 + A2 * L2,
solver.method = 'glm',
predict.method = 'predict.glm')
q1 <- modelObj::buildModelObj(model = ~ A1 * L1,
solver.method = 'glm',
predict.method = 'predict.glm')
valueSearchAIPW <- function(eta){
reg <- cbind( (data$L1 > eta),
(data$L2 > eta) * (1 - data$S2),
(data$L3 > eta) * (1 - data$S3),
(data$L4 > eta) * (1 - data$S4) )
Q4 <- value_AIPW_md(
moPS = list(p1, p2, p3, p4),
moQ = list(q1, q2, q3, q4),
data = dataLDL,
y = dataLDL$Y,
txName = c("A1", "A2", "A3", "A4"),
regime = reg
)
value = -Q4$valueHat
return(value)
}
eta_grid = seq(10, 300, 10)
# value_AIPW = sapply(eta_grid, valueSearchAIPW)
# resultQ4 = rbind(value_AIPW, eta_grid)[,order(value_AIPW)]
resultQ4 = readRDS("resultQ4.RDS")
resultQ4
Vopt4b = resultQ4[1,1]
p41 <- buildModelObjSubset(model = ~ 1,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd41',
dp = 4L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p42 <- buildModelObjSubset(model = ~ L4,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd42',
dp = 4L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p31 <- buildModelObjSubset(model = ~ 1,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd31',
dp = 3L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p32 <- buildModelObjSubset(model = ~ L3,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd32',
dp = 3L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p21 <- buildModelObjSubset(model = ~ 1,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd21',
dp = 2L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p22 <- buildModelObjSubset(model = ~ L2,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd22',
dp = 2L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
p1 <- buildModelObjSubset(model = ~ L4,
solver.method = 'glm',
solver.args = list("family"='binomial'),
subset = 'd1',
dp = 1L,
predict.method = 'predict.glm',
predict.args = list("type"='response'))
fSet1 <- function(data){
subsets <- list(list("d1",c(0,1)))
txOpts <- rep(x = 'd1', times = nrow(x = data))
return(list("subsets" = subsets, "txOpts" = txOpts))
}
fSet <- list(fSet1, fSet2, fSet3, fSet4)
reg1 <- function(eta1, data){as.integer(data$L1 > eta1)}
reg2 <- function(eta2, data){as.integer((data$L2 > eta2) * (1 - data$S2))}
reg3 <- function(eta3, data){as.integer((data$L3 > eta3) * (1 - data$S3))}
reg4 <- function(eta4, data){as.integer((data$L4 > eta4) * (1 - data$S4))}
reg <- list(reg1, reg2, reg3, reg4)
modelQ5a <- readRDS('resultQ5.Rdata')
etaQ5a <- regimeCoef(object = modelQ5a)
etaQ5a
Vopt5a = -estimator(modelQ5a)
# c)
q1MainSub <- buildModelObjSubset(model = ~ L1,
solver.method = 'lm',
subset = "d1",
dp=1,
predict.method = 'predict.lm')
q1ContSub <- buildModelObjSubset(model = ~ L1,
solver.method = 'lm',
subset = "d1",
dp=1,
predict.method = 'predict.lm')
modelQ5c = readRDS("modelQ5c.RDS")
etaQ5c = regimeCoef(modelQ5c)
etaQ5c
cbind(etaQ5a, etaQ5c)
(Vopt5c =  estimator(modelQ5c))
cbind(Vopt5a, Vopt5c)
(Vopt5c =  -estimator(modelQ5c))
cbind(Vopt5a, Vopt5c)
value = cbind(round(rbind( Vopt2b, Vopt3b, Vopt4b, Vopt6a), 4), method=c("Q_Learn", "IPW", "AIPW" ,"MSM"))
96.63+40.56+13
30+150+80
30+150+80
260/4
rm(list = ls())
library(knitr) # kable
library(readr) # read_delim
library(dplyr) # manipulate data
library(Amelia) # missing value imputation
#### Load Data regression ----------------------------------------------------------------------------------------
main_path= "F:/zxy/Project/TAA/TAA_Consulting/"
setwd(main_path);getwd()
data <- readr::read_delim("./data/tabular data_final.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
data = rename(data,  Y1_initiation = init_composite, Y2_adoption = adoption_score, Y3_routinization = rout_composite,
X1_readiness = TAA_capability, X2_integration = integrate_composite, X3_firmSize = Q26_num,
X4_global = Domestic_International, X5_manag = manag_composite, X6_compet = comp_composite,
X7_regulatory = gov_composite)
data_imput = data = as.data.frame( data %>% select(Y1_initiation, Y2_adoption, Y3_routinization, X1_readiness, X2_integration, X3_firmSize,
X4_global, X5_manag, X6_compet, X7_regulatory) )
names(data)
summary(data)
missmap(data)
m = 5 # number of simulated datsets to create # See definition of m in ?amelia()
data_amelia <- amelia(x = data, logs="X3_firmSize", m = 5)
# Average the imputations between different simulated datasets
for( col in c(6:7)){
temp=numeric()
for (i in 1:m){
temp = cbind(temp, data_amelia$imputations[[i]][,col])
}
data_imput[,col] = apply(temp, 1, mean)
}
data_new = scale(data_imput)
#### Missing Value Visualization ----------------------------------------------------------------------------------------
data_orig <- readr::read_delim("./data/tabular data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
par(mfrow=c(1,1))
data_orig <- as.data.frame(data_orig)
missmap(data_orig, main="Missingness Map")
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
compare.density(data_amelia, var="X3_firmSize")
compare.density(data_amelia, var="X4_global", legend=F)
#### Missing Value Visualization ----------------------------------------------------------------------------------------
data_orig <- readr::read_delim("./data/tabular data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
par(mfrow=c(1,1))
data_orig <- as.data.frame(data_orig)
missmap(data_orig, main="Missingness Map")
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
compare.density(data_amelia, var="X3_firmSize")
compare.density(data_amelia, var="X4_global", legend=F)
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
boxplot(data_imput$X3_firmSize, main="Boxplot for X3_firmSize", horizontal=T)
compare.density(data_amelia, var="X3_firmSize")
boxplot(data_imput$X3_firmSize[-c(27, 46)], main="Boxplot for X3_firmSize", horizontal=T)
order(data_imput$X3_firmSize)
boxplot(data_imput$X3_firmSize, main="Boxplot for X3_firmSize", horizontal=T)
install.packages(c("coefplot", "ggcorrplot"))
#### Missing Value Visualization ----------------------------------------------------------------------------------------
data_orig <- readr::read_delim("./data/tabular data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
par(mfrow=c(1,1))
data_orig <- as.data.frame(data_orig)
missmap(data_orig, main="Missingness Map")
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
compare.density(data_amelia, var="X3_firmSize")
?amelia()
data$X4_global
as.factor(data$X4_global)
data$X4_global <- as.factor(data$X4_global)
names(data)
summary(data)
missmap(data)
m = 5 # number of simulated datsets to create # See definition of m in ?amelia()
data_amelia <- amelia(x = data, logs="X3_firmSize", m = 5)
# Average the imputations between different simulated datasets
for( col in c(6:7)){
temp=numeric()
for (i in 1:m){
temp = cbind(temp, data_amelia$imputations[[i]][,col])
}
data_imput[,col] = apply(temp, 1, mean)
}
data_new = scale(data_imput)
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
data_new
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
data_amelia <- amelia(x = data, logs="X3_firmSize", m = 5)
data_amelia <- amelia(x = data, logs="X3_firmSize", noms="X4_global" ,m = 5)
# Average the imputations between different simulated datasets
for( col in c(6:7)){
temp=numeric()
for (i in 1:m){
temp = cbind(temp, data_amelia$imputations[[i]][,col])
}
data_imput[,col] = apply(temp, 1, mean)
}
data_new = scale(data_imput)
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
compare.density(data_amelia, var="X3_firmSize")
par(mfrow=c(2,1), mar=c(2, 3, 2, 3))
plot(data_amelia)
compare.density(data_amelia, var="X3_firmSize")
compare.density(data_amelia, var="X4_global", legend=F)
compare.density(data_amelia, var="X4_global", legend=F)
data_amelia$imputations$imp1$X4_global
data_imput$X4_global
plot( data_imput$X4_global )
boxplot( data_imput$X4_global )
=======
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
lst <- nlm(function(lambda){-log.like(y,x)},0.01)
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lst
lambda0_minimum <- log.like.lambda0(y)
lambda0_minimum
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambdaMLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambdaMLE)
}
i
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambdaMLE)
}
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sigma2MLE,lambda_MLE)
}
mean(results[,3])
?cov
covhat <- cov(results)
covhat
100*convhat
covhat <- cov(results)
100*covhat
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(123456)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sqrt(sigma2MLE),lambda_MLE)
}
covhat <- cov(results)
100*covhat
log.like <- function(y,lambda){
ylambda <- (y^lambda-1)/lambda
muhat <- mean(ylambda)
sigma2hat <- mean((ylambda-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((ylambda-muhat)^2)+(lambda-1)*sum(log(y))
return(loglikelihood)
}
log.like.lambda0 <- function(y){
muhat <- mean(log(y))
sigma2hat <- mean((log(y)-muhat)^2)
n <- length(y)
loglikelihood <- -n/2*log(2*pi*sigma2hat)-1/(2*sigma2hat)*sum((log(y)-muhat)^2)-sum(log(y))
return(loglikelihood)
}
boxcox <- function(y,lambda){
if(lambda==0){
return(log(y))
}else{
return((y^lambda-1)/lambda)
}
}
set.seed(1)
results <- matrix(0,nrow=1000,ncol=3)
for(i in 1:1000){
y <- exp(rnorm(100,1,1))
lst <- nlm(function(lambda){-log.like(y,lambda)},0.01)
lambda_minimum <- lst$minimum
lambda_MLE <- lst$estimate
lambda0_minimum <- -log.like.lambda0(y)
lambda_MLE <- ifelse(lambda_minimum<lambda0_minimum,lambda_MLE,0)
ylambdaMLE <- boxcox(y,lambda_MLE)
muMLE <- mean(ylambdaMLE)
sigma2MLE <- mean((ylambdaMLE-muMLE)^2)
results[i,] <- c(muMLE,sqrt(sigma2MLE),lambda_MLE)
}
covhat <- cov(results)
100*covhat
library(iso)
install.packages("Iso")
library(Iso)
y <- c(0.38753188, 0.33352923, 1.69926631, 1.51233891, 3.71256346,
6.54700165, 6.78007386, 8.3102987 , 7.96376751, 8.37754041)
pava(y)
k <- 3
nc <- 10
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
1-pchisq(qchisq(0.95,k-1),2,nc)
k <- 3
nc <- 10
1-pchisq(qchisq(0.95,k-1),2,nc)
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 10
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 20
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
k <- 3
nc <- 10
1-pchisq(qchisq(0.95,k-1),2,nc)
n <- 5
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 10
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
n <- 20
1-pf(qf(0.95,k-1,k*(n-1)),k-1,k*(n-1),nc)
pbinom(7,20,0.3)
pbinom(7,20,0.3)-pbinom(1,20,0.3)
dbinom(7,20,0.3)
pbinom(4,15,0.5)+1-pbinom(10,15,0.5)
pbinom(7,15,0.5)
dbinom(6,15,0.5)
pbinom(12,15,0.5)-pbinom(2,15,0.5)
pbinom(4,15,0.5)
pbinom(4,15,0.5)-pbinom(2,15,0.5)+pbinom(12,15,0.5)-pbinom(10,15,0.5)
0.1184692*0.9926147
1-pbinorm(19,25,0.75)
1-pbinom(19,25,0.75)
(4^2-2^2)/50+2*(5^2-4^2)/50
10-sqrt(50/3)
dbinom(9,10,15/16)
exp(-1)-exp(-(1.5)^3)
(-log(0.25))^(1/3)*5
(-log(0.75))^(1/3)*5
(-log(0.25))^(1/3)*5-(-log(0.75))^(1/3)*5
1-pnorm((7.5-225*0.05)/sqrt(225*0.05*0.95))
1-pnorm((8-225*0.05)/sqrt(225*0.05*0.95))
1-pnorm((7-225*0.05)/sqrt(225*0.05*0.95))
pnorm((14.5-225*0.05)/sqrt(225*0.05*0.95))-pnorm((5.5-225*0.05)/sqrt(225*0.05*0.95))
0.2*0.8/1000
sqrt(0.00016)
sqrt(0.2*0.8/1000)
68.3/2+50
qnorm(0.8415)
1.000642*0.01264911+0.2
0.2126572-0.2
0.2+sqrt(0.00016)*qnorm(0.6)
0.6*0.4/100
0.6*0.4/200
qnorm(0.6)
0.2-0.01264911*0.2533471
l1trendfilter <- function(y,lambda,k,dt_perc=1,N=1e5,thetaInit=NULL,
sigma2Init=NULL,alpha=NULL,alphaAdjust=F,
alpha_shape=NULL,alpha_rate=NULL,t=1,correct_manner='none'){
n <- length(y)
D <- getD(k,n)
#prepare the arrays for sample storation
theta_samples <- matrix(0,nrow=N,ncol=n)
sigma2_samples <- rep(0,N)
alpha_samples <- rep(0,N)
#set initial values of theta,sigma2 and alpha
if(is.null(thetaInit)){
theta <- theta_samples[1,] <- y
}else{
theta <- theta_samples[1,] <- thetaInit
}
if(is.null(sigma2Init)){
sigma2 <- sigma2_samples[1] <- 1
}else{
sigma2 <- sigma2_samples[1] <- sigma2Init
}
alpha_samples[1] <- alpha
#ensure that alpha_shape and alpha_rate are specified if alphaAdjust=T
if(alphaAdjust){
if(is.null(alpha_shape)|is.null(alpha_rate)){
stop('alpha_shape and alpha_rate must be specified!')
}
}
#prepare the gradient and proximal operator
gradf <- function(theta){(theta-y)/sigma2}
prox <- function(theta){glmgen::trendfilter(theta,k=k,lambda=lambda*alpha)$beta}
logpilambda <- function(theta,prox_proj_theta){
loglikelihood <- -norm(y-theta,'2')^2/(2*sigma2)-alpha*Matrix::norm(D%*%prox_proj_theta,'1')-norm(theta-prox_proj_theta,'2')^2/(2*lambda)
return(loglikelihood)
}
logpi <- function(theta){-norm(y-theta,'2')^2/(2*sigma2)-alpha*Matrix::norm(D%*%theta,'1')}
#MCMC sampling
pb <- progress::progress_bar$new(
format = "  sampling [:bar] :percent eta: :eta",
total = N-1, clear = FALSE, width= 60)
if(correct_manner=='none'){
for(i in 1:(N-1)){
Lf <- 1/sigma2
thetanew <- MYULA_tstep(theta,lambda,Lf,dt_perc,gradf,prox,t)
theta <- theta_samples[i+1,] <- thetanew
sigma2 <- sigma2_samples[i+1] <- invgamma::rinvgamma(1, n/2, rate = sum((y-theta)^2)/2)
alpha_samples[i+1] <- alpha
pb$tick()
}
}else{
accept_number <- 0
for(i in 1:(N-1)){
Lf <- 1/sigma2
if(correct_manner=='approximate'){
result <- MYMALA(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='approximate',logpilambda=logpilambda)
}else{
result <- MYMALA(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='exact',logpi=logpi)
}
theta <- theta_samples[i+1,] <- result$thetanew
if(result$accept){
accept_number <- accept_number+1
}
sigma2 <- sigma2_samples[i+1] <- invgamma::rinvgamma(1, n/2, rate = sum((y-theta)^2)/2)
if(alphaAdjust){
alpha <- rgamma(1,alpha_shape,alpha_rate+Matrix::norm(D%*%theta,'1'))
}
alpha_samples[i+1] <- alpha
pb$tick()
}
print(sprintf("%s%% of theta MCMC iterates accepted (%s total iterates)",100*accept_number/N,N))
}
return(list(theta_samples=theta_samples,sigma2_samples=sigma2_samples,
alpha_samples=alpha_samples))
}
MYMALA <- function(theta,lambda,Lf,dt_perc,gradf,prox,correct_manner='approximate',
logpilambda=NULL,logpi=NULL){
n <- length(theta)
#L is the lipschitz constant of the gradient of U
L <- Lf+1/lambda
#same gamma as in MYULA paper
gamma <- dt_perc/L
#gradient of f at current iterate theta
gradf_theta <- gradf(theta)
#proximal projection of current iterate theta
prox_proj_theta <- prox(theta)
#the constant part of the transition kernel
normal_mean_forward <- (1-gamma/lambda)*theta-gamma*gradf_theta+gamma/lambda*prox_proj_theta
#add Gaussian noise to get the new MCMC iterate
thetanew <- normal_mean_forward + sqrt(2*gamma)*rnorm(n)
accept <- T
#gradient of f at new iterate thetanew
gradf_thetanew <- gradf(thetanew)
#proximal projection of new iterate thetanew
prox_proj_thetanew <- prox(thetanew)
#the constant part of the inverse transition kernel
normal_mean_backward <- (1-gamma/lambda)*thetanew-gamma*gradf_thetanew+gamma/lambda*prox_proj_thetanew
log_q_diff <- (norm(thetanew-normal_mean_forward,'2')^2-norm(theta-normal_mean_backward,'2')^2)/(4*gamma)
if(correct_manner=='approximate'){
if(is.null(logpilambda)){
stop('logpilambda must be specified for approximate correction')
}
log_pilambda_diff <- logpilambda(thetanew,prox_proj_thetanew)-logpilambda(theta,prox_proj_theta)
log_ratio <- min(0,log_pilambda_diff+log_q_diff)
}else{
if(is.null(logpi)){
stop('logpi must be specified for exact correction')
}
log_pi_diff <- logpi(thetanew)-logpi(theta)
log_ratio <- min(0,log_pi_diff+log_q_diff)
}
#actual correction step
if(log(runif(1))>log_ratio){
thetanew <- theta
accept <- FALSE
}
return(list(thetanew=thetanew,accept=accept))
}
f <- Vectorize(function(x){if(x<=5){x} else if(x<=15){10-x} else{x-20}})
x <- seq(0,20,length=100)
y <- f(x)+rnorm(100)
getD <- function(k, n){
D <- Matrix::sparseMatrix(i=c(1:(n-1),1:(n-1)),j=c(1:(n-1),2:n),
x=c(rep(-1,n-1),rep(1,n-1)),dims=list(n-1,n))
if(k>=1){
for(i in 1:k){
leftD <- Matrix::sparseMatrix(i=c(1:(n-i-1),1:(n-i-1)),j=c(1:(n-i-1),2:(n-i)),
x=c(rep(-1,n-i-1),rep(1,n-i-1)),dims=list(n-i-1,n-i))
D <- leftD %*% D
}}
return(D)
}
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=T,alpha_shape=100,alpha_rate=1,correct_manner='exact')
alpha_samples <- samples$alpha_samples
mean(alpha_samples)
posterior_means <- apply(theta_samples,2,mean)
sigma2_samples <- samples$sigma2_samples
theta_samples <- samples$theta_samples
posterior_medians <- apply(theta_samples,2,quantile,probs=0.05)
lower_conflim <- apply(theta_samples,2,quantile,probs=0.025)
upper_conflim <- apply(theta_samples,2,quantile,probs=0.975)
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_means,type='l',col='blue')
ines(x,posterior_medians,type='l',col='blue')
lines(x,posterior_medians,type='l',col='blue')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='exact')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='exact')
samples <- l1trendfilter(y,0.01,1,0.1,N=1e5,alpha=10,alphaAdjust=F,correct_manner='approximate')
alpha_samples <- samples$alpha_samples
theta_samples <- samples$theta_samples
sigma2_samples <- samples$sigma2_samples
posterior_medians <- apply(theta_samples,2,quantile,probs=0.05)
lower_conflim <- apply(theta_samples,2,quantile,probs=0.025)
upper_conflim <- apply(theta_samples,2,quantile,probs=0.975)
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
posterior_medians <- apply(theta_samples,2,quantile,probs=0.5)
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
hist(alpha_samples,breaks=100,col='blue',main='')
par(mfrow=c(1,2))
plot(x,y,type='p',col='red')
polygon(c(x,rev(x)),c(lower_conflim,rev(upper_conflim)),col = "lightblue", border = FALSE)
lines(x,posterior_medians,type='l',col='blue')
hist(sigma2_samples,breaks=100,xlab='sigma2',col='blue',main='')
abline(v=1, col='red')
library(devtools)
load_all()
data <- read_delim("./data/tabular data_impute.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
library(readr)
setwd('C:/Users/Qiang/Desktop/Quick access/course/TAA_Consulting')
data <- read_delim("./data/tabular data_impute.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
View(data)
Y <- data[,c(1,2,3)]
multi_reg <- lm(Y~-1+.,data=data)
Y <- data.matrix(data[,c(1,2,3)])
multi_reg <- lm(Y~-1+.,data=data)
multi_reg
multi_reg <- lm(Y1_initiation~-1+.,data=data)
multi_reg
X <- data.matrix(data[,-c(1,2,3)])
View(X)
multi_reg <- lm(Y1_initiation~.-1,data=X)
X <- data[,-c(1,2,3)]
multi_reg <- lm(Y1_initiation~.-1,data=X)
multi_reg <- lm(Y~.-1,data=X)
multi_reg
lm(Y[,1]~.-1,data=X)
mvsum[[1]]
mvsum <- summary(multi_reg)
mvsum[[1]]
mvsum[[2]]
mvsum[[3]]
multi_reg1 <- lm(Y~.-1-X1_readiness,data=X)
anova(multi_reg, multi_reg1, test="Wilks")
multi_reg <- lm(Y~.-1,data=X)
multi_reg1 <- lm(Y~.-1-X1_readiness,data=X)
anova(multi_reg, multi_reg1, test="Wilks")
anova(multi_reg, multi_reg1, test="Pillai")
anova(multi_reg, multi_reg1, test="Hotelling-Lawley")
anova(multi_reg, multi_reg1, test="Roy")
anova(multi_reg, multi_reg1, test="Wilks")
anova(multi_reg, multi_reg1, test="Pillai")
anova(multi_reg, multi_reg1, test="Hotelling-Lawley")
anova(multi_reg, multi_reg1, test="Roy")
)
multi_reg2 <- lm(Y~.-1-X2_integration,data=X)
anova(multi_reg, multi_reg2, test="Wilks")
anova(multi_reg, multi_reg2, test="Pillai")
anova(multi_reg, multi_reg2, test="Hotelling-Lawley")
anova(multi_reg, multi_reg2, test="Roy")
multi_reg3 <- lm(Y~.-1-X3_firmsize,data=X)
multi_reg3 <- lm(Y~.-1-X3_firmSize,data=X)
anova(multi_reg, multi_reg3, test="Wilks")
anova(multi_reg, multi_reg3, test="Pillai")
anova(multi_reg, multi_reg3, test="Hotelling-Lawley")
anova(multi_reg, multi_reg3, test="Roy")
multi_reg4 <- lm(Y~.-1-X4_global,data=X)
anova(multi_reg, multi_reg4, test="Wilks")
anova(multi_reg, multi_reg4, test="Pillai")
anova(multi_reg, multi_reg4, test="Hotelling-Lawley")
anova(multi_reg, multi_reg4, test="Roy")
multi_reg5 <- lm(Y~.-1-X5_manag,data=X)
anova(multi_reg, multi_reg5, test="Wilks")
anova(multi_reg, multi_reg5, test="Pillai")
anova(multi_reg, multi_reg5, test="Hotelling-Lawley")
anova(multi_reg, multi_reg5, test="Roy")
multi_reg6 <- lm(Y~.-1-X6_compet,data=X)
anova(multi_reg, multi_reg6, test="Wilks")
anova(multi_reg, multi_reg6, test="Pillai")
anova(multi_reg, multi_reg6, test="Hotelling-Lawley")
anova(multi_reg, multi_reg6, test="Roy")
multi_reg7 <- lm(Y~.-1-X7_regulatory,data=X)
anova(multi_reg, multi_reg7, test="Wilks")
anova(multi_reg, multi_reg7, test="Pillai")
anova(multi_reg, multi_reg7, test="Hotelling-Lawley")
anova(multi_reg, multi_reg7, test="Roy")
>>>>>>> 4ef8bdb1e0f8ee6f66be54cfd9d9cc5fa250a4ac
